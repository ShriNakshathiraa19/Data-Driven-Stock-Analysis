{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3760d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = rROOT_DIR = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\GProject02 Dataset\\data (1)\"\n",
    "\n",
    "\n",
    "stock_data = defaultdict(list)\n",
    "\n",
    "for month_folder in os.listdir(ROOT_DIR):\n",
    "    month_path = os.path.join(ROOT_DIR, month_folder)\n",
    "    if os.path.isdir(month_path):\n",
    "        for file_name in os.listdir(month_path):\n",
    "            if file_name.endswith(\".yaml\") or file_name.endswith(\".yml\"):\n",
    "                file_path = os.path.join(month_path, file_name)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        entries = yaml.safe_load(f)\n",
    "                        for entry in entries:\n",
    "                            ticker = entry.get(\"Ticker\")\n",
    "                            if ticker:\n",
    "                                stock_data[ticker].append(entry)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189dc8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 50 CSV files written to folder: C:\\Users\\Admin\\OneDrive\\Desktop\\GProject02 Dataset\\data (1)\\output_csvs\n"
     ]
    }
   ],
   "source": [
    "# Create output folder inside the root path\n",
    "output_dir = os.path.join(ROOT_DIR, \"output_csvs\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Write one CSV per Ticker\n",
    "for ticker, records in stock_data.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    df.sort_values(by=\"date\", inplace=True)\n",
    "    df.to_csv(os.path.join(output_dir, f\"{ticker}.csv\"), index=False)\n",
    "\n",
    "print(f\"{len(stock_data)} CSV files written to folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6595fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV files found: 50\n",
      "Sample files: ['ADANIENT.csv', 'ADANIPORTS.csv', 'APOLLOHOSP.csv', 'ASIANPAINT.csv', 'AXISBANK.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = os.path.join(ROOT_DIR, \"output_csvs\")\n",
    "csv_files = os.listdir(output_dir)\n",
    "\n",
    "print(f\"Total CSV files found: {len(csv_files)}\")\n",
    "print(\"Sample files:\", csv_files[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856ef8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your sector mapping file\n",
    "sector_path = r\"C:\\Users\\Admin\\Downloads\\Sector_data - Sheet1.csv\"\n",
    "sector_df = pd.read_csv(sector_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc445bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>sector</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADANI ENTERPRISES</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>ADANIGREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADANI PORTS &amp; SEZ</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>ADANIPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APOLLO HOSPITALS</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>APOLLOHOSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASIAN PAINTS</td>\n",
       "      <td>PAINTS</td>\n",
       "      <td>ASIANPAINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AXIS BANK</td>\n",
       "      <td>BANKING</td>\n",
       "      <td>AXISBANK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             COMPANY         sector      Ticker\n",
       "0  ADANI ENTERPRISES  MISCELLANEOUS  ADANIGREEN\n",
       "1  ADANI PORTS & SEZ  MISCELLANEOUS  ADANIPORTS\n",
       "2   APOLLO HOSPITALS  MISCELLANEOUS  APOLLOHOSP\n",
       "3       ASIAN PAINTS         PAINTS  ASIANPAINT\n",
       "4          AXIS BANK        BANKING    AXISBANK"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload fresh sector mapping\n",
    "sector_path = r\"c:\\Users\\Admin\\Downloads\\Sector_data - Sheet1.csv\"\n",
    "sector_df = pd.read_csv(sector_path)\n",
    "\n",
    "# Now do the cleaning again\n",
    "sector_df['Ticker'] = sector_df['Symbol'].apply(lambda x: x.split(\":\")[-1].strip())\n",
    "sector_df = sector_df.drop(columns=['Symbol'])\n",
    "\n",
    "sector_df.head()  # Optional: to confirm it worked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5f772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All enriched CSVs saved to: C:\\Users\\Admin\\OneDrive\\Desktop\\GProject02 Dataset\\data (1)\\output_csvs_enriched\n"
     ]
    }
   ],
   "source": [
    "enriched_dir = os.path.join(ROOT_DIR, \"output_csvs_enriched\")\n",
    "os.makedirs(enriched_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(output_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        ticker = file.replace(\".csv\", \"\")\n",
    "        match = sector_df[sector_df[\"Ticker\"] == ticker]\n",
    "\n",
    "        if not match.empty:\n",
    "            company = match[\"COMPANY\"].values[0]\n",
    "            sector = match[\"sector\"].values[0]\n",
    "\n",
    "            df = pd.read_csv(os.path.join(output_dir, file))\n",
    "            df[\"COMPANY\"] = company\n",
    "            df[\"sector\"] = sector\n",
    "            df[\"Ticker\"] = ticker\n",
    "\n",
    "            df.to_csv(os.path.join(enriched_dir, file), index=False)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No sector info found for: {ticker}\")\n",
    "\n",
    "print(\"All enriched CSVs saved to:\", enriched_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc268ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error uploading ADANIENT.csv: (pymysql.err.OperationalError) (1292, \"Incorrect date value: '03-10-2023 05:30' for column 'date' at row 1\")\n",
      "[SQL: INSERT INTO stocks (`Ticker`, close, date, high, low, month, open, volume, `COMPANY`, sector) VALUES (%(Ticker)s, %(close)s, %(date)s, %(high)s, %(low)s, %(month)s, %(open)s, %(volume)s, %(COMPANY)s, %(sector)s)]\n",
      "[parameters: [{'Ticker': 'ADANIENT', 'close': 2387.25, 'date': '03-10-2023 05:30', 'high': 2424.9, 'low': 2372.0, 'month': '2023-10', 'open': 2418.0, 'volume': 2019899, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}, {'Ticker': 'ADANIENT', 'close': 2464.95, 'date': '04-10-2023 05:30', 'high': 2502.75, 'low': 2392.25, 'month': '2023-10', 'open': 2402.2, 'volume': 2857377, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}, {'Ticker': 'ADANIENT', 'close': 2466.35, 'date': '05-10-2023 05:30', 'high': 2486.5, 'low': 2446.4, 'month': '2023-10', 'open': 2477.95, 'volume': 1132455, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}, {'Ticker': 'ADANIENT', 'close': 2478.1, 'date': '06-10-2023 05:30', 'high': 2514.95, 'low': 2466.05, 'month': '2023-10', 'open': 2466.35, 'volume': 1510035, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}, {'Ticker': 'ADANIENT', 'close': 2442.6, 'date': '09-10-2023 05:30', 'high': 2459.7, 'low': 2411.3, 'month': '2023-10', 'open': 2440.0, 'volume': 1408224, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}, {'Ticker': 'ADANIENT', 'close': 2498.3, 'date': '10-10-2023 05:30', 'high': 2517.95, 'low': 2443.0, 'month': '2023-10', 'open': 2443.0, 'volume': 1771910, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}, {'Ticker': 'ADANIENT', 'close': 2488.6, 'date': '11-10-2023 05:30', 'high': 2538.0, 'low': 2482.5, 'month': '2023-10', 'open': 2533.9, 'volume': 1627836, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}, {'Ticker': 'ADANIENT', 'close': 2506.35, 'date': '12-10-2023 05:30', 'high': 2521.75, 'low': 2490.65, 'month': '2023-10', 'open': 2499.9, 'volume': 1804818, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}  ... displaying 10 of 284 total bound parameter sets ...  {'Ticker': 'ADANIENT', 'close': 2183.65, 'date': '21-11-2024 05:30', 'high': 2539.35, 'low': 2155.05, 'month': '2024-11', 'open': 2539.35, 'volume': 21796668, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}, {'Ticker': 'ADANIENT', 'close': 2228.0, 'date': '22-11-2024 05:30', 'high': 2289.7, 'low': 2025.0, 'month': '2024-11', 'open': 2101.0, 'volume': 20939196, 'COMPANY': 'ADANI ENTERPRISES', 'sector': 'MISCELLANEOUS'}]]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "‚úÖ Uploaded: ADANIPORTS.csv\n",
      "‚úÖ Uploaded: APOLLOHOSP.csv\n",
      "‚úÖ Uploaded: ASIANPAINT.csv\n",
      "‚úÖ Uploaded: AXISBANK.csv\n",
      "‚úÖ Uploaded: BAJAJ-AUTO.csv\n",
      "‚úÖ Uploaded: BAJAJFINSV.csv\n",
      "‚úÖ Uploaded: BAJFINANCE.csv\n",
      "‚úÖ Uploaded: BEL.csv\n",
      "‚úÖ Uploaded: BHARTIARTL.csv\n",
      "‚úÖ Uploaded: BPCL.csv\n",
      "‚úÖ Uploaded: BRITANNIA.csv\n",
      "‚úÖ Uploaded: CIPLA.csv\n",
      "‚úÖ Uploaded: COALINDIA.csv\n",
      "‚úÖ Uploaded: DRREDDY.csv\n",
      "‚úÖ Uploaded: EICHERMOT.csv\n",
      "‚úÖ Uploaded: GRASIM.csv\n",
      "‚úÖ Uploaded: HCLTECH.csv\n",
      "‚úÖ Uploaded: HDFCBANK.csv\n",
      "‚úÖ Uploaded: HDFCLIFE.csv\n",
      "‚úÖ Uploaded: HEROMOTOCO.csv\n",
      "‚úÖ Uploaded: HINDALCO.csv\n",
      "‚úÖ Uploaded: HINDUNILVR.csv\n",
      "‚úÖ Uploaded: ICICIBANK.csv\n",
      "‚úÖ Uploaded: INDUSINDBK.csv\n",
      "‚úÖ Uploaded: INFY.csv\n",
      "‚úÖ Uploaded: ITC.csv\n",
      "‚úÖ Uploaded: JSWSTEEL.csv\n",
      "‚úÖ Uploaded: KOTAKBANK.csv\n",
      "‚úÖ Uploaded: LT.csv\n",
      "‚úÖ Uploaded: M&M.csv\n",
      "‚úÖ Uploaded: MARUTI.csv\n",
      "‚úÖ Uploaded: NESTLEIND.csv\n",
      "‚úÖ Uploaded: NTPC.csv\n",
      "‚úÖ Uploaded: ONGC.csv\n",
      "‚úÖ Uploaded: POWERGRID.csv\n",
      "‚úÖ Uploaded: RELIANCE.csv\n",
      "‚úÖ Uploaded: SBILIFE.csv\n",
      "‚úÖ Uploaded: SBIN.csv\n",
      "‚úÖ Uploaded: SHRIRAMFIN.csv\n",
      "‚úÖ Uploaded: SUNPHARMA.csv\n",
      "‚úÖ Uploaded: TATACONSUM.csv\n",
      "‚úÖ Uploaded: TATAMOTORS.csv\n",
      "‚úÖ Uploaded: TATASTEEL.csv\n",
      "‚úÖ Uploaded: TCS.csv\n",
      "‚úÖ Uploaded: TECHM.csv\n",
      "‚úÖ Uploaded: TITAN.csv\n",
      "‚úÖ Uploaded: TRENT.csv\n",
      "‚úÖ Uploaded: ULTRACEMCO.csv\n",
      "‚úÖ Uploaded: WIPRO.csv\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Replace with your actual MySQL credentials\n",
    "username = \"root\"\n",
    "password = \"root\"  # Replace this\n",
    "host = \"localhost\"\n",
    "port = 3306\n",
    "database = \"stock_data\"\n",
    "\n",
    "# Path to enriched CSVs folder\n",
    "enriched_dir = os.path.join(ROOT_DIR, \"output_csvs_enriched\")\n",
    "\n",
    "# SQLAlchemy engine\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "# Upload each file\n",
    "for file in os.listdir(enriched_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(enriched_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        try:\n",
    "            df.to_sql(\"stocks\", con=engine, if_exists=\"append\", index=False)\n",
    "            print(f\"Uploaded: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e5671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: ADANIENT.csv\n",
      "‚úÖ Uploaded: ADANIPORTS.csv\n",
      "‚úÖ Uploaded: APOLLOHOSP.csv\n",
      "‚úÖ Uploaded: ASIANPAINT.csv\n",
      "‚úÖ Uploaded: AXISBANK.csv\n",
      "‚úÖ Uploaded: BAJAJ-AUTO.csv\n",
      "‚úÖ Uploaded: BAJAJFINSV.csv\n",
      "‚úÖ Uploaded: BAJFINANCE.csv\n",
      "‚úÖ Uploaded: BEL.csv\n",
      "‚úÖ Uploaded: BHARTIARTL.csv\n",
      "‚úÖ Uploaded: BPCL.csv\n",
      "‚úÖ Uploaded: BRITANNIA.csv\n",
      "‚úÖ Uploaded: CIPLA.csv\n",
      "‚úÖ Uploaded: COALINDIA.csv\n",
      "‚úÖ Uploaded: DRREDDY.csv\n",
      "‚úÖ Uploaded: EICHERMOT.csv\n",
      "‚úÖ Uploaded: GRASIM.csv\n",
      "‚úÖ Uploaded: HCLTECH.csv\n",
      "‚úÖ Uploaded: HDFCBANK.csv\n",
      "‚úÖ Uploaded: HDFCLIFE.csv\n",
      "‚úÖ Uploaded: HEROMOTOCO.csv\n",
      "‚úÖ Uploaded: HINDALCO.csv\n",
      "‚úÖ Uploaded: HINDUNILVR.csv\n",
      "‚úÖ Uploaded: ICICIBANK.csv\n",
      "‚úÖ Uploaded: INDUSINDBK.csv\n",
      "‚úÖ Uploaded: INFY.csv\n",
      "‚úÖ Uploaded: ITC.csv\n",
      "‚úÖ Uploaded: JSWSTEEL.csv\n",
      "‚úÖ Uploaded: KOTAKBANK.csv\n",
      "‚úÖ Uploaded: LT.csv\n",
      "‚úÖ Uploaded: M&M.csv\n",
      "‚úÖ Uploaded: MARUTI.csv\n",
      "‚úÖ Uploaded: NESTLEIND.csv\n",
      "‚úÖ Uploaded: NTPC.csv\n",
      "‚úÖ Uploaded: ONGC.csv\n",
      "‚úÖ Uploaded: POWERGRID.csv\n",
      "‚úÖ Uploaded: RELIANCE.csv\n",
      "‚úÖ Uploaded: SBILIFE.csv\n",
      "‚úÖ Uploaded: SBIN.csv\n",
      "‚úÖ Uploaded: SHRIRAMFIN.csv\n",
      "‚úÖ Uploaded: SUNPHARMA.csv\n",
      "‚úÖ Uploaded: TATACONSUM.csv\n",
      "‚úÖ Uploaded: TATAMOTORS.csv\n",
      "‚úÖ Uploaded: TATASTEEL.csv\n",
      "‚úÖ Uploaded: TCS.csv\n",
      "‚úÖ Uploaded: TECHM.csv\n",
      "‚úÖ Uploaded: TITAN.csv\n",
      "‚úÖ Uploaded: TRENT.csv\n",
      "‚úÖ Uploaded: ULTRACEMCO.csv\n",
      "‚úÖ Uploaded: WIPRO.csv\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:root@localhost:3306/stock_data\")\n",
    "\n",
    "enriched_dir = os.path.join(ROOT_DIR, \"output_csvs_enriched\")\n",
    "\n",
    "for file in os.listdir(enriched_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(enriched_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        try:\n",
    "            # üîß Fix the date format\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date\n",
    "\n",
    "            # üöÄ Upload to MySQL\n",
    "            df.to_sql(\"stocks\", con=engine, if_exists=\"append\", index=False)\n",
    "            print(f\"‚úÖ Uploaded: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0903ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:root@localhost:3306/stock_data\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_sql(\"SELECT * FROM stocks\", engine)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
